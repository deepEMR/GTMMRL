{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load NOTEEVENTS start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caoyu/anaconda3/envs/torch_kg_txt/lib/python3.7/site-packages/ipykernel_launcher.py:153: DtypeWarning: Columns (4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load NOTEEVENTS successfully!\n",
      "Get discharge summary successfully!\n",
      "Preprocess notes successfully!\n",
      "save successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re, json \n",
    "import argparse\n",
    "import os\n",
    "\n",
    "# px, dxprx\n",
    "\n",
    "ROOT_PATH = 'result-dxprx'\n",
    "if not os.path.isdir(ROOT_PATH):\n",
    "    os.mkdir(ROOT_PATH)\n",
    "\n",
    "LOAD_FILE_PATH = '/home/caoyu/project/GraphCLHealth/data/mimiciii/NOTEEVENTS.csv'\n",
    "SAVE_FILE_PATH = f'{ROOT_PATH}/sections.csv'\n",
    "\n",
    "\n",
    "'''\n",
    "Table --> Sections\n",
    "\n",
    "1. load NOTEEVENTS.csv\n",
    "\n",
    "2. get discharge sumamry notes\n",
    "    a) NOTEVENTS.CATEGORY = 'Discharge Summary'\n",
    "    b) NOTEVENTS.DESCRIPTION = 'Report'\n",
    "    c) eliminate a short-note\n",
    "\n",
    "3. preprocess discharge sumamry notes\n",
    "    a) clean text\n",
    "    b) split sections by headers\n",
    "    \n",
    "4. save csv file\n",
    "    a) PK: NOTEVENTS.ROW_ID\n",
    "    b) TEXT: string(doubled-list)\n",
    "    \n",
    "'''\n",
    "\n",
    "def load_noteevents(file_path):\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # dataframe dtype config\n",
    "    df.CHARTDATE = pd.to_datetime(df.CHARTDATE, format='%Y-%m-%d', errors='raise')\n",
    "    df.CHARTTIME = pd.to_datetime(df.CHARTTIME, format='%Y-%m-%d %H:%M:%S', errors='raise')\n",
    "    df.STORETIME = pd.to_datetime(df.STORETIME)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_csv_file(csv_data, file_path):\n",
    "    csv_data.to_csv(file_path, index=False)\n",
    "    print('save successfully!')\n",
    "\n",
    "\n",
    "def get_discharge_summary(df_notevents):\n",
    "\n",
    "    cond1 = (df_notevents.CATEGORY == 'Discharge summary')\n",
    "    cond2 = (df_notevents.DESCRIPTION == 'Report')\n",
    "\n",
    "    df_discharge_smmary = df_notevents[cond1&cond2]\n",
    "    df_discharge_smmary = df_discharge_smmary[['ROW_ID', 'TEXT']]\n",
    "    \n",
    "    # eliminate a short-note (subject_id=30561, hadm_id=178941)\n",
    "    df_discharge_smmary = df_discharge_smmary[df_discharge_smmary.TEXT.apply(lambda x: len(x) > 100)]\n",
    "\n",
    "    return df_discharge_smmary\n",
    "\n",
    "\n",
    "def pattern_repl(matchobj):\n",
    "    # Return a replacement string to be used for match object\n",
    "    return ' '.rjust(len(matchobj.group(0)))  \n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    # 1. Replace [**Patterns**] with spaces.\n",
    "    text = re.sub(r'\\[\\*\\*.*?\\*\\*\\]', pattern_repl, text)\n",
    "    \n",
    "    # 2. Replace `_` with spaces.\n",
    "    new_text = re.sub(r'_', ' ', text)\n",
    "    \n",
    "    return new_text\n",
    "\n",
    "\n",
    "def split_section(text):\n",
    "    headers, sections = [], []\n",
    "#     pattern = \"^([A-z0-9 ]+)(:)|Discharge Date:|Sex:|JOB#:|Unit No:|FOLLOW-UP PLANS:\"\n",
    "    except_pattern = \"(?!(Sig:)|(disp:))\"\n",
    "    include_keywords = \"(Discharge Date:)|(Sex:)|(JOB#:)|(Unit No:)|(FOLLOW-UP PLANS:)\"\n",
    "    pattern = \"^\" + except_pattern + \"([A-z0-9 ]+)(:)|\" + include_keywords\n",
    "    SEPERATORS = re.compile(pattern, re.I | re.M)\n",
    "    start = 0\n",
    "    \n",
    "    for matcher in SEPERATORS.finditer(text):\n",
    "        # cut off by the position of later SEPERATOR\n",
    "        end = matcher.start()\n",
    "        if end != start: # except for first line\n",
    "            section = text[start:end]\n",
    "            if ':' not in section: #\n",
    "                pass\n",
    "            else:\n",
    "                section = section[len(header):].strip() # except for header in section\n",
    "                sections.append(section)\n",
    "        start = end\n",
    "        end = matcher.end()\n",
    "        \n",
    "        # collect each title in the beginning of section\n",
    "        header = text[start:end].lower()\n",
    "        headers.append(header)\n",
    "        \n",
    "    # add last section\n",
    "    section = text[start:]\n",
    "    section = section[len(header):].strip()\n",
    "    sections.append(section)\n",
    "    \n",
    "    return headers, sections\n",
    "\n",
    "\n",
    "def clean_header(header):\n",
    "    # delete : (colon)\n",
    "    header = re.sub(r',', '', header)\n",
    "    new_header = re.sub(r':', '', header)\n",
    "    new_header = new_header.strip()\n",
    "    return new_header\n",
    "\n",
    "\n",
    "def clean_section(section):\n",
    "    # Replace multiple spaces with a space.\n",
    "    new_section = ' '.join(section.split())\n",
    "    return new_section\n",
    "\n",
    "\n",
    "def preprocess_discharge_summary(text):\n",
    "    text = clean_text(text)\n",
    "    headers, sections = split_section(text)\n",
    "    \n",
    "    # for duplicated keys problem when formulate dict type data\n",
    "#     for idx in range(len(headers)):\n",
    "#         h = clean_header(headers[idx])\n",
    "#         s = clean_section(sections[idx])\n",
    "#         result[h] = s\n",
    "    \n",
    "    new_headers, new_sections = [], []\n",
    "    for idx in range(len(headers)):\n",
    "        h = clean_header(headers[idx])\n",
    "        s = clean_section(sections[idx])\n",
    "        new_headers.append(h)\n",
    "        new_sections.append(s)\n",
    "    return [new_headers, new_sections]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    print('Load NOTEEVENTS start!')\n",
    "    data = load_noteevents(file_path=LOAD_FILE_PATH)\n",
    "    print('Load NOTEEVENTS successfully!')\n",
    "    data       = get_discharge_summary(data)\n",
    "    print('Get discharge summary successfully!')\n",
    "    notes      = data.TEXT.apply(lambda x: json.dumps(preprocess_discharge_summary(x)))\n",
    "    print('Preprocess notes successfully!')\n",
    "    new_data   = pd.concat([data.ROW_ID, notes], axis=1)\n",
    "\n",
    "    save_csv_file(csv_data=new_data, file_path=SAVE_FILE_PATH)\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ----- for debug start -----\n",
    "### 查看 note headers 有哪些类型？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re, json \n",
    "import os\n",
    "import argparse\n",
    "\n",
    "\n",
    "LOAD_FILE_PATH = os.path.join(ROOT_PATH,'sections.csv')\n",
    "SAVE_FILE_PATH = os.path.join(ROOT_PATH,'p_sections.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_file(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "def extract_dx_and_prx_section(text):\n",
    "    #prx_section = []\n",
    "    dx_section = \"\"\n",
    "    text = json.loads(text) # change string format to dict\n",
    "    headers, sections = text[0], text[1]\n",
    "    \n",
    "    print(headers)\n",
    "    \n",
    "    pos1, pos2, pos3, pos4 = -999, -999, -999, -999\n",
    "    \n",
    "    h1 = 'discharge medications'\n",
    "    h2 = 'discharge disposition'\n",
    "    h3 = 'discharge diagnosis'\n",
    "    h4 = 'discharge condition'\n",
    "    h5 = 'laboratory studies'\n",
    "    \n",
    "    if h1 in headers:\n",
    "        pos1 = headers.index(h1)\n",
    "    if h2 in headers:\n",
    "        pos2 = headers.index(h2)\n",
    "    if h3 in headers:\n",
    "        pos3 = headers.index(h3)\n",
    "    if h4 in headers:\n",
    "        pos4 = headers.index(h4)\n",
    "\n",
    "    if pos1 + pos2 + pos3 + pos4 > 0: # have all together\n",
    "        if pos1 < pos2 < pos3 < pos4: # well organized\n",
    "#             px_headers = headers[pos1:pos2]\n",
    "            dx_section = ' '.join(sections[pos3:pos4])\n",
    "    \n",
    "    query = 'major surgical or invasive procedure'\n",
    "    try:\n",
    "        pos = headers.index(query)\n",
    "    except:\n",
    "        pos = \"\"\n",
    "        \n",
    "    if pos:\n",
    "        prx_section = sections[pos]\n",
    "    else:\n",
    "        prx_section = \"\"\n",
    "            \n",
    "    return {'dx':dx_section, 'prx':prx_section}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data       = load_csv_file(file_path=LOAD_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55176"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174</td>\n",
       "      <td>[[\"admission date\", \"discharge date\", \"service...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175</td>\n",
       "      <td>[[\"admission date\", \"discharge date\", \"date of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID                                               TEXT\n",
       "0     174  [[\"admission date\", \"discharge date\", \"service...\n",
       "1     175  [[\"admission date\", \"discharge date\", \"date of..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admission date', 'discharge date', 'date of birth', 'sex', 'service', 'history of present illness', 'review of systems is negative for the following', 'past medical history', 'medications on admission', 'allergies', 'family history', 'social history', 'physical exam at time of admission', 'laboratory studies', 'brief summary of hospital course', 'discharge condition', 'discharge status', 'discharge medications', 'follow-up plans', 'final diagnoses', 'dictated by', 'd', 't', 'job#']\n",
      "['admission date', 'discharge date', 'service', 'allergies', 'attending', 'chief complaint', 'major surgical or invasive procedure', 'history of present illness', 'past medical history', 'pmh', 'social history', 'social history', 'family history', 'family history', 'physical exam', 'brief hospital course', 'medications on admission', 'discharge medications', 'discharge disposition', 'facility', 'discharge diagnosis', 'discharge condition', 'discharge instructions', 'completed by']\n"
     ]
    }
   ],
   "source": [
    "notes      = data[1:3].TEXT.apply(lambda x: extract_dx_and_prx_section(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ----- for debug end -----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 继续下一步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract section from notes successfully!\n",
      "save successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re, json \n",
    "import os\n",
    "import argparse\n",
    "\n",
    "\n",
    "LOAD_FILE_PATH = os.path.join(ROOT_PATH,'sections.csv')\n",
    "SAVE_FILE_PATH = os.path.join(ROOT_PATH,'p_sections.csv')\n",
    "\n",
    "\n",
    "'''\n",
    "preprocessing for mimic discharge summary note\n",
    "\n",
    "1. load NOTEEVENTS.csv\n",
    "\n",
    "2. get discharge sumamry notes\n",
    "    a) NOTEVENTS.CATEGORY = 'Discharge Summary'\n",
    "    b) NOTEVENTS.DESCRIPTION = 'Report'\n",
    "    c) eliminate a short-note\n",
    "\n",
    "3. preprocess discharge sumamry notes\n",
    "    a) clean text\n",
    "    b) split sections by headers\n",
    "    \n",
    "4. save csv file\n",
    "    a) PK: NOTEVENTS.ROW_ID\n",
    "    b) TEXT: string(doubled-list)\n",
    "    \n",
    "'''\n",
    "\n",
    "def load_csv_file(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_csv_file(csv_data, file_path):\n",
    "    csv_data.to_csv(file_path, index=False)\n",
    "    return print('save successfully!')\n",
    "\n",
    "\n",
    "def extract_px_section(text):\n",
    "    px_section = []\n",
    "    text = json.loads(text) # change string format to dict\n",
    "    headers, sections = text[0], text[1]\n",
    "    \n",
    "    pos1, pos2, pos3, pos4 = -999, -999, -999, -999\n",
    "    \n",
    "    h1 = 'discharge medications'\n",
    "    h2 = 'discharge disposition'\n",
    "    h3 = 'discharge diagnosis'\n",
    "    h4 = 'discharge condition'\n",
    "    \n",
    "#     h5 = 'FINAL DIAGNOSES:'\n",
    "    \n",
    "    \n",
    "    if h1 in headers:\n",
    "        pos1 = headers.index(h1)\n",
    "    if h2 in headers:\n",
    "        pos2 = headers.index(h2)\n",
    "    if h3 in headers:\n",
    "        pos3 = headers.index(h3)\n",
    "    if h4 in headers:\n",
    "        pos4 = headers.index(h4)\n",
    "\n",
    "    if pos1 + pos2 + pos3 + pos4 > 0: # have all together\n",
    "        if pos1 < pos2 < pos3 < pos4: # well organized\n",
    "#             px_headers = headers[pos1:pos2]\n",
    "            px_section = ' '.join(sections[pos1:pos2])\n",
    "        else:\n",
    "            px_section = ''\n",
    "    else:\n",
    "        px_section = ''\n",
    "            \n",
    "    return {'px':px_section}\n",
    "\n",
    "def extract_prx_section(text):\n",
    "    prx_section = []\n",
    "    text = json.loads(text) # change string format to dict\n",
    "    headers, sections = text[0], text[1]\n",
    "    \n",
    "    query = 'major surgical or invasive procedure'\n",
    "    try:\n",
    "        pos = headers.index(query)\n",
    "    except:\n",
    "        pos = \"\"\n",
    "        \n",
    "    if pos:\n",
    "        prx_section = sections[pos]\n",
    "            \n",
    "    return {'prx':prx_section}\n",
    "\n",
    "def extract_dx_and_prx_section(text):\n",
    "    #prx_section = []\n",
    "    dx_section = \"\"\n",
    "    text = json.loads(text) # change string format to dict\n",
    "    headers, sections = text[0], text[1]\n",
    "    \n",
    "    pos1, pos2, pos3, pos4 = -999, -999, -999, -999\n",
    "    \n",
    "    h1 = 'discharge medications'\n",
    "    h2 = 'discharge disposition'\n",
    "    h3 = 'discharge diagnosis'\n",
    "    h4 = 'discharge condition'\n",
    "    \n",
    "    if h1 in headers:\n",
    "        pos1 = headers.index(h1)\n",
    "    if h2 in headers:\n",
    "        pos2 = headers.index(h2)\n",
    "    if h3 in headers:\n",
    "        pos3 = headers.index(h3)\n",
    "    if h4 in headers:\n",
    "        pos4 = headers.index(h4)\n",
    "\n",
    "    if pos1 + pos2 + pos3 + pos4 > 0: # have all together\n",
    "        if pos1 < pos2 < pos3 < pos4: # well organized\n",
    "#             px_headers = headers[pos1:pos2]\n",
    "            dx_section = ' '.join(sections[pos3:pos4])\n",
    "    \n",
    "    query = 'major surgical or invasive procedure'\n",
    "    try:\n",
    "        pos = headers.index(query)\n",
    "    except:\n",
    "        pos = \"\"\n",
    "        \n",
    "    if pos:\n",
    "        prx_section = sections[pos]\n",
    "    else:\n",
    "        prx_section = \"\"\n",
    "            \n",
    "    return {'dx':dx_section, 'prx':prx_section}\n",
    "\n",
    "# def main():\n",
    "data       = load_csv_file(file_path=LOAD_FILE_PATH)\n",
    "notes      = data.TEXT.apply(lambda x: extract_dx_and_prx_section(x))\n",
    "print('extract section from notes successfully!')\n",
    "new_data   = pd.concat([data.ROW_ID, notes], axis=1)\n",
    "    \n",
    "save_csv_file(csv_data=new_data, file_path=SAVE_FILE_PATH)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caoyu/anaconda3/envs/torch_kg_txt/lib/python3.7/site-packages/ipykernel_launcher.py:53: DtypeWarning: Columns (4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data len: {} 32919\n",
      "data1 len: {} 32919\n",
      "save successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re, json\n",
    "import argparse\n",
    "import torch\n",
    "import os\n",
    "\n",
    "import spacy, scispacy\n",
    "\n",
    "\n",
    "NOTE_PATH = os.path.join('/home/caoyu/project/GraphCLHealth/data/mimiciii','NOTEEVENTS.csv')\n",
    "LOAD_FILE_PATH = os.path.join(ROOT_PATH,'p_sections.csv')\n",
    "SEC_SAVE_FILE_PATH = os.path.join(ROOT_PATH,'p_sections.txt')\n",
    "ADM_SAVE_FILE_PATH = os.path.join(ROOT_PATH,'p_hadm_ids.txt')\n",
    "\n",
    "def load_csv_file(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_file(data, file_path,txt=False):\n",
    "#     with open(file_path, \"w\") as file:\n",
    "    torch.save([(hadm_id, text) for hadm_id, text in zip(data[0],data[1])],os.path.join(ROOT_PATH,'p_sections'))\n",
    "    return print('save successfully!')\n",
    "\n",
    "\n",
    "def preprocess_scispacy(nlp, section_text):\n",
    "    section_text_p = ' '.join([token.text for token in nlp(section_text)])\n",
    "    return section_text_p\n",
    "\n",
    "\n",
    "def main():\n",
    "#     data       = load_csv_file(file_path=LOAD_FILE_PATH)\n",
    "    data = new_data\n",
    "    # data = data.iloc[:10]\n",
    "    \n",
    "    # not na \n",
    "    data = data[data.TEXT.notna()]\n",
    "\n",
    "    # length > 200\n",
    "    data = data[data.TEXT.apply(lambda x: sum([len(elem.split()) for elem in x.values()]) > 5)]\n",
    "\n",
    "    # delete \"\"\n",
    "#     data1 = data.copy()\n",
    "#     data1.TEXT = data.TEXT.apply(lambda x: x[1:-1])\n",
    "\n",
    "    # preprocessed by scispacy\n",
    "#     nlp = spacy.load(\"en_core_sci_sm\")\n",
    "#     data.TEXT = data1.TEXT.apply(lambda x: preprocess_scispacy(nlp, x))\n",
    "#     del data1\n",
    "    print('preprocess successfully!')\n",
    "\n",
    "    # recover and extract full info of data(subject_id, hamd_id)\n",
    "    noteevents = load_csv_file(file_path=NOTE_PATH)\n",
    "    noteevents = noteevents[['ROW_ID', 'SUBJECT_ID', 'HADM_ID']]\n",
    "\n",
    "    # data=p / noteevents\n",
    "    data1 = noteevents[noteevents.ROW_ID.isin(data.ROW_ID)]\n",
    "    \n",
    "    # save txt file\n",
    "    print('data len: {}', len(data))\n",
    "#     save_file(data=data.TEXT, file_path=SEC_SAVE_FILE_PATH)\n",
    "    hadm_id = data1.HADM_ID.astype(int).astype(str)\n",
    "    print('data1 len: {}', len(hadm_id))\n",
    "    save_file(data=(hadm_id,data.TEXT), file_path=ADM_SAVE_FILE_PATH, txt=True)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_kg_txt",
   "language": "python",
   "name": "torch_kg_txt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
